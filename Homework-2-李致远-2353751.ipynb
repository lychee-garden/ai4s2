{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b8af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports and setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(126)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ba6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: Helper functions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def load_data_with_date(data_path, train_end, pred_start, pred_end):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "    target_col = [c for c in df.columns if 'MW' in c.upper()][0]\n",
    "    train_data = df[df.index <= pd.to_datetime(train_end)][target_col].values\n",
    "    train_data = train_data[~np.isnan(train_data)]\n",
    "    pred_actual = df[(df.index >= pd.to_datetime(pred_start)) & (df.index <= pd.to_datetime(pred_end))][target_col].values\n",
    "    pred_actual = pred_actual[~np.isnan(pred_actual)]\n",
    "    return train_data, pred_actual\n",
    "\n",
    "def create_sequences(data, seq_len=96, pred_len=24):\n",
    "    return np.array([data[i:i+seq_len] for i in range(len(data)-seq_len-pred_len+1)]), \\\n",
    "           np.array([data[i+seq_len:i+seq_len+pred_len] for i in range(len(data)-seq_len-pred_len+1)])\n",
    "\n",
    "def smape_loss(y_true, y_pred):\n",
    "    import tensorflow as tf\n",
    "    eps = tf.keras.backend.epsilon()\n",
    "    return tf.reduce_mean(2.0 * tf.abs(y_true - y_pred) / (tf.abs(y_true) + tf.abs(y_pred) + eps))\n",
    "\n",
    "def build_model(seq_len, pred_len, improved=True):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    if improved:\n",
    "        return Sequential([\n",
    "            LSTM(128, return_sequences=True, input_shape=(seq_len, 1)), Dropout(0.3),\n",
    "            LSTM(128, return_sequences=True), Dropout(0.3),\n",
    "            LSTM(64, return_sequences=False), Dropout(0.2),\n",
    "            Dense(64, activation='relu'), Dense(32, activation='relu'), Dense(pred_len)\n",
    "        ])\n",
    "    else:\n",
    "        return Sequential([\n",
    "            LSTM(64, return_sequences=True, input_shape=(seq_len, 1)), Dropout(0.2),\n",
    "            LSTM(64, return_sequences=False), Dropout(0.2),\n",
    "            Dense(32), Dense(pred_len)\n",
    "        ])\n",
    "\n",
    "def iterative_forecast(model, X_init, pred_hours, batch_size=24):\n",
    "    predictions, current_seq = [], X_init.copy()\n",
    "    for i in range(0, pred_hours, batch_size):\n",
    "        pred_batch = model.predict(current_seq.reshape(1, current_seq.shape[0], 1), verbose=0)[0]\n",
    "        predictions.append(pred_batch if i + batch_size <= pred_hours else pred_batch[:pred_hours - i])\n",
    "        if i + batch_size <= pred_hours:\n",
    "            current_seq = np.concatenate([current_seq[batch_size:], pred_batch])\n",
    "    return np.concatenate(predictions)\n",
    "\n",
    "def calculate_smape(y_true, y_pred):\n",
    "    \"\"\"Calculate sMAPE value\"\"\"\n",
    "    eps = 1e-8\n",
    "    return np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + eps))\n",
    "\n",
    "def plot_model_architecture():\n",
    "    try:\n",
    "        from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "        ax.set_xlim(0, 10)\n",
    "        ax.set_ylim(0, 10)\n",
    "        ax.axis('off')\n",
    "        boxes = [('Raw Data', 1, 8), ('Normalization', 3.5, 8), ('Sequence Creation', 6, 8), ('LSTM Model', 3.5, 6),\n",
    "                 ('Training', 1, 4), ('Iterative Forecast', 3.5, 4), ('Denormalization', 6, 4), ('Evaluation', 3.5, 2)]\n",
    "        for text, x, y in boxes:\n",
    "            ax.add_patch(FancyBboxPatch((x-0.75, y-0.4), 1.5, 0.8, boxstyle=\"round,pad=0.1\",\n",
    "                                       edgecolor='black', facecolor='lightblue', linewidth=2))\n",
    "            ax.text(x, y, text, ha='center', va='center', fontsize=9, weight='bold')\n",
    "        arrows = [(1, 8, 3.5, 8), (3.5, 8, 6, 8), (6, 7.6, 3.5, 6.4), (3.5, 5.6, 1, 4.4),\n",
    "                  (1, 4, 3.5, 4), (3.5, 4, 6, 4), (6, 3.6, 3.5, 2.4)]\n",
    "        for x1, y1, x2, y2 in arrows:\n",
    "            ax.add_patch(FancyArrowPatch((x1, y1), (x2, y2), arrowstyle='->', mutation_scale=20,\n",
    "                                       linewidth=2, color='darkblue'))\n",
    "        ax.set_title('Neural Network Model Architecture', fontsize=14, weight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('model_architecture.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"Model architecture diagram saved to model_architecture.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting model architecture: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aaff62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: Separate training and prediction functions\n",
    "\n",
    "def train_model(data_path, train_end, seq_len=96, problem_name='', retrain=False, epochs=100, batch_size=64):\n",
    "    \"\"\"\n",
    "    Train the LSTM model for time series forecasting.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_path: path to the CSV file\n",
    "    - train_end: end date for training data (e.g., '2017-12-31')\n",
    "    - seq_len: sequence length for LSTM input\n",
    "    - problem_name: name identifier for the problem (used for file naming)\n",
    "    - retrain: if True, force retraining even if model exists\n",
    "    - epochs: number of training epochs\n",
    "    - batch_size: batch size for training\n",
    "    \n",
    "    Returns:\n",
    "    - model: trained Keras model\n",
    "    - scaler: fitted StandardScaler\n",
    "    - train_scaled: scaled training data\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Model: {problem_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load training data\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "    target_col = [c for c in df.columns if 'MW' in c.upper()][0]\n",
    "    train_data = df[df.index <= pd.to_datetime(train_end)][target_col].values\n",
    "    train_data = train_data[~np.isnan(train_data)]\n",
    "    print(f\"Training data: {len(train_data)} points\")\n",
    "    \n",
    "    # Generate model and scaler file paths (use .weights.h5 for save_weights_only=True)\n",
    "    model_name = 'model_problem_a.weights.h5' if 'A' in problem_name else 'model_problem_b.weights.h5'\n",
    "    scaler_name = 'scaler_problem_a.pkl' if 'A' in problem_name else 'scaler_problem_b.pkl'\n",
    "    \n",
    "    # Prepare data\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_data.reshape(-1, 1)).flatten()\n",
    "    pred_len = 24\n",
    "    \n",
    "    X_train, y_train = create_sequences(train_scaled, seq_len=seq_len, pred_len=pred_len)\n",
    "    X_train_r = np.array(X_train, dtype=np.float32).reshape((len(X_train), seq_len, 1))\n",
    "    y_train_all = np.array(y_train, dtype=np.float32)\n",
    "    \n",
    "    print(f\"Training sequences: {len(X_train)}\")\n",
    "    \n",
    "    try:\n",
    "        from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        \n",
    "        # Check if saved model exists and not forcing retrain\n",
    "        if not retrain and os.path.exists(model_name) and os.path.exists(scaler_name):\n",
    "            print(f\"Loading saved model from {model_name}...\")\n",
    "            model = build_model(seq_len, pred_len, improved=True)\n",
    "            model.compile(optimizer='adam', loss=smape_loss, metrics=['mae'])\n",
    "            model.load_weights(model_name)\n",
    "            with open(scaler_name, 'rb') as f:\n",
    "                scaler = pickle.load(f)\n",
    "            train_scaled = scaler.transform(train_data.reshape(-1, 1)).flatten()\n",
    "            print(\"Model and scaler loaded successfully!\")\n",
    "            return model, scaler, train_scaled\n",
    "        \n",
    "        # Train new model\n",
    "        if retrain:\n",
    "            print(\"Force retraining model...\")\n",
    "        else:\n",
    "            print(\"Training new model...\")\n",
    "        \n",
    "        model = build_model(seq_len, pred_len, improved=True)\n",
    "        model.compile(optimizer='adam', loss=smape_loss, metrics=['mae'])\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='loss', save_best_only=True, \n",
    "                                   save_weights_only=True, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "        \n",
    "        print(f\"Starting training for {epochs} epochs...\")\n",
    "        history = model.fit(X_train_r, y_train_all, epochs=epochs, batch_size=batch_size,\n",
    "                           callbacks=[early_stopping, checkpoint], verbose=1)\n",
    "        \n",
    "        # Save scaler\n",
    "        with open(scaler_name, 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        print(f\"\\n✓ Model saved to {model_name}\")\n",
    "        print(f\"✓ Scaler saved to {scaler_name}\")\n",
    "        print(f\"✓ Training completed!\")\n",
    "        \n",
    "        return model, scaler, train_scaled\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def predict_with_model(model, scaler, train_scaled, data_path, pred_start, pred_end, \n",
    "                      seq_len=96, problem_name=''):\n",
    "    \"\"\"\n",
    "    Use trained model to make predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained Keras model\n",
    "    - scaler: fitted StandardScaler\n",
    "    - train_scaled: scaled training data (last seq_len points will be used)\n",
    "    - data_path: path to the CSV file\n",
    "    - pred_start: start date for prediction\n",
    "    - pred_end: end date for prediction\n",
    "    - seq_len: sequence length (must match training)\n",
    "    - problem_name: name identifier for the problem\n",
    "    \n",
    "    Returns:\n",
    "    - smape: sMAPE metric value\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Making Predictions: {problem_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if model is None or scaler is None:\n",
    "        print(\"Error: Model or scaler is None. Please train the model first.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load actual values for comparison\n",
    "        df = pd.read_csv(data_path)\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "        df.set_index('Datetime', inplace=True)\n",
    "        target_col = [c for c in df.columns if 'MW' in c.upper()][0]\n",
    "        pred_actual = df[(df.index >= pd.to_datetime(pred_start)) & \n",
    "                         (df.index <= pd.to_datetime(pred_end))][target_col].values\n",
    "        pred_actual = pred_actual[~np.isnan(pred_actual)]\n",
    "        print(f\"Prediction period: {len(pred_actual)} hours\")\n",
    "        \n",
    "        # Make predictions\n",
    "        print(\"Generating predictions...\")\n",
    "        long_term_pred = iterative_forecast(model, train_scaled[-seq_len:], len(pred_actual))[:len(pred_actual)]\n",
    "        long_term_pred_actual = scaler.inverse_transform(long_term_pred.reshape(-1, 1)).flatten()\n",
    "        pred_actual_vals = scaler.inverse_transform(pred_actual.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Calculate sMAPE\n",
    "        smape = calculate_smape(pred_actual_vals, long_term_pred_actual)\n",
    "        print(f\"\\nForecasting Results - SMAPE: {smape:.4f}\")\n",
    "        \n",
    "        # Plot results\n",
    "        plot_len = min(2000, len(pred_actual_vals))\n",
    "        time_idx = pd.date_range(start=pd.to_datetime(pred_start), periods=plot_len, freq='H')\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.plot(time_idx, pred_actual_vals[:plot_len], label='Actual', linewidth=1, alpha=0.7)\n",
    "        plt.plot(time_idx, long_term_pred_actual[:plot_len], label='Predicted', linewidth=1, linestyle='--', alpha=0.7)\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Energy Consumption (MW)')\n",
    "        plt.title(f'{problem_name} (First {plot_len} Hours)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        filename = 'problem_a_forecast.png' if 'A' in problem_name else 'long_term_forecast.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"✓ Plot saved to {filename}\")\n",
    "        \n",
    "        return smape\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "def forecast(data_path, train_end, pred_start, pred_end, seq_len=96, problem_name='', \n",
    "             retrain=False, epochs=100, batch_size=64):\n",
    "    \"\"\"\n",
    "    Complete workflow: train model and make predictions.\n",
    "    This function combines train_model and predict_with_model for convenience.\n",
    "    \"\"\"\n",
    "    # Step 1: Train model\n",
    "    model, scaler, train_scaled = train_model(data_path, train_end, seq_len, problem_name, retrain, epochs, batch_size)\n",
    "    \n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Make predictions\n",
    "    smape = predict_with_model(model, scaler, train_scaled, data_path, pred_start, pred_end, \n",
    "                              seq_len, problem_name)\n",
    "    \n",
    "    return smape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b106bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture diagram saved to model_architecture.png\n",
      "============================================================\n",
      "Problem 1A: Training Model\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Training Model: Problem A: Forecasting (2018-01 to 2018-08)\n",
      "============================================================\n",
      "Training data: 116116 points\n",
      "Training sequences: 115997\n",
      "Training new model...\n",
      "Starting training for 100 epochs...\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# Plot model architecture\n",
    "plot_model_architecture()\n",
    "\n",
    "# Problem 1A: Step 1 - Train the model\n",
    "print(\"=\"*60)\n",
    "print(\"Problem 1A: Training Model\")\n",
    "print(\"=\"*60)\n",
    "model_a, scaler_a, train_scaled_a = train_model(\n",
    "    'EnergyConsumption_hourly.csv', \n",
    "    '2017-12-31', \n",
    "    seq_len=96, \n",
    "    problem_name='Problem A: Forecasting (2018-01 to 2018-08)', \n",
    "    retrain=False,\n",
    "    epochs=100,\n",
    "    batch_size=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe93c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1A: Step 2 - Make predictions after training completes\n",
    "if model_a is not None:\n",
    "    smape_a = predict_with_model(\n",
    "        model_a, scaler_a, train_scaled_a,\n",
    "        'EnergyConsumption_hourly.csv',\n",
    "        '2018-01-01', '2018-08-31',\n",
    "        seq_len=96,\n",
    "        problem_name='Problem A: Forecasting (2018-01 to 2018-08)'\n",
    "    )\n",
    "else:\n",
    "    print(\"Training failed, cannot make predictions.\")\n",
    "    smape_a = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564698cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1B: Step 1 - Train the model\n",
    "print(\"=\"*60)\n",
    "print(\"Problem 1B: Training Model\")\n",
    "print(\"=\"*60)\n",
    "model_b, scaler_b, train_scaled_b = train_model(\n",
    "    'EnergyConsumption_hourly.csv', \n",
    "    '2016-12-31', \n",
    "    seq_len=168, \n",
    "    problem_name='Problem B: Long-Term Forecasting (2017-01 to 2018-08)', \n",
    "    retrain=False,\n",
    "    epochs=100,\n",
    "    batch_size=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1B: Step 2 - Make predictions after training completes\n",
    "if model_b is not None:\n",
    "    smape_b = predict_with_model(\n",
    "        model_b, scaler_b, train_scaled_b,\n",
    "        'EnergyConsumption_hourly.csv',\n",
    "        '2017-01-01', '2018-08-31',\n",
    "        seq_len=168,\n",
    "        problem_name='Problem B: Long-Term Forecasting (2017-01 to 2018-08)'\n",
    "    )\n",
    "else:\n",
    "    print(\"Training failed, cannot make predictions.\")\n",
    "    smape_b = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: Summary\n",
    "print(\"\\n\" + \"=\"*60 + \"\\nSummary:\")\n",
    "if smape_a is not None:\n",
    "    print(f\"  Problem A (2018-01 to 2018-08) - SMAPE: {smape_a:.4f}\")\n",
    "if smape_b is not None:\n",
    "    print(f\"  Problem B (2017-01 to 2018-08) - SMAPE: {smape_b:.4f}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Imports\n",
    "import random\n",
    "import math\n",
    "from matplotlib import colors\n",
    "random.seed(126)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Ising Model Simulation Functions\n",
    "def initialize_grid(dim):\n",
    "    return np.random.choice([-1, 1], size=(dim, dim))\n",
    "\n",
    "def energy_change(grid, i, j):\n",
    "    n = grid.shape[0]\n",
    "    left, right = (i - 1) % n, (i + 1) % n\n",
    "    up, down = (j + 1) % n, (j - 1) % n\n",
    "    return 2 * grid[i, j] * (grid[left, j] + grid[right, j] + grid[i, up] + grid[i, down])\n",
    "\n",
    "def spin_flip(grid, T):\n",
    "    n = grid.shape[0]\n",
    "    i, j = random.randint(0, n - 1), random.randint(0, n - 1)\n",
    "    delta_E = energy_change(grid, i, j)\n",
    "    if delta_E < 0 or random.random() < math.exp(-delta_E / T):\n",
    "        grid[i, j] = -grid[i, j]\n",
    "    return grid\n",
    "\n",
    "def ising_simulation(n, T, steps=100):\n",
    "    \"\"\"Simulate 2D Ising model using Metropolis algorithm\"\"\"\n",
    "    grid = initialize_grid(n)\n",
    "    for step in range(steps):\n",
    "        for _ in range(n * n):\n",
    "            grid = spin_flip(grid, T)\n",
    "    return grid\n",
    "\n",
    "def generate_data(size, num_temp, temp_min=1.0, temp_max=3.5, repeat=1, max_iter=None):\n",
    "    \"\"\"Generate training/test data from Ising model simulations\"\"\"\n",
    "    if max_iter is None:\n",
    "        max_iter = size**2\n",
    "    X = np.zeros((num_temp * repeat, size**2))\n",
    "    y_label = np.zeros((num_temp * repeat, 1))\n",
    "    y_temp = np.zeros((num_temp * repeat, 1))\n",
    "    temps = np.linspace(temp_min, temp_max, num=num_temp)\n",
    "    for i in range(repeat):\n",
    "        for j in range(num_temp):\n",
    "            grid = ising_simulation(size, temps[j], max_iter)\n",
    "            X[i*num_temp + j, :] = grid.reshape(1, grid.size)\n",
    "            y_label[i*num_temp + j, :] = (temps[j] > 2.269)\n",
    "            y_temp[i*num_temp + j, :] = temps[j]\n",
    "            print(f\"Generated {i*num_temp + j + 1}/{num_temp * repeat}\", end='\\r')\n",
    "    print()\n",
    "    return X, y_label, y_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b66f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Model Building Functions\n",
    "def build_ising_model(input_dim, task_type='classification'):\n",
    "    \"\"\"Build neural network model (TensorFlow or sklearn)\"\"\"\n",
    "    try:\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense, Dropout\n",
    "        from tensorflow.keras.optimizers import Adam\n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "            Dropout(0.3), Dense(64, activation='relu'),\n",
    "            Dropout(0.2), Dense(32, activation='relu'),\n",
    "            Dense(1, activation='sigmoid' if task_type == 'classification' else None)\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(0.001),\n",
    "                     loss='binary_crossentropy' if task_type == 'classification' else 'mean_absolute_error',\n",
    "                     metrics=['accuracy' if task_type == 'classification' else 'mae'])\n",
    "        return model, 'keras'\n",
    "    except ImportError:\n",
    "        from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "        if task_type == 'classification':\n",
    "            return MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=500, \n",
    "                                random_state=126, early_stopping=True), 'sklearn'\n",
    "        else:\n",
    "            return MLPRegressor(hidden_layer_sizes=(128, 64, 32), max_iter=500,\n",
    "                              random_state=126, early_stopping=True), 'sklearn'\n",
    "\n",
    "def plot_model_flowchart(task_name, model_type, save_path):\n",
    "    \"\"\"Create model flowchart\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.axis('off')\n",
    "    layers = ['Input\\n(625)', 'Dense\\n(128)', 'Dense\\n(64)', 'Dense\\n(32)', \n",
    "              'Output\\n(1)' if model_type == 'regression' else 'Output\\n(0/1)']\n",
    "    y_pos = np.linspace(0.9, 0.1, len(layers))\n",
    "    for i, (layer, y) in enumerate(zip(layers, y_pos)):\n",
    "        rect = plt.Rectangle((0.4 - 0.08, y - 0.04), 0.16, 0.08,\n",
    "                           facecolor='lightblue', edgecolor='black', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(0.4, y, layer, ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "        if i < len(layers) - 1:\n",
    "            ax.arrow(0.4, y - 0.04, 0, -(y_pos[i] - y_pos[i+1] - 0.08),\n",
    "                    head_width=0.015, head_length=0.015, fc='black', ec='black')\n",
    "    ax.text(0.5, 0.95, f'{task_name} Model Flowchart', ha='center', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def train_and_evaluate(model, model_type, X_train, y_train, X_test, y_test, task_name):\n",
    "    \"\"\"Train model and return predictions\"\"\"\n",
    "    if model_type == 'keras':\n",
    "        from tensorflow.keras.callbacks import EarlyStopping\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2,\n",
    "                 callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "                 verbose=0)\n",
    "        y_pred = model.predict(X_test, verbose=0)\n",
    "        if task_name == 'classification':\n",
    "            y_pred = (y_pred > 0.5).astype(int).flatten()\n",
    "        else:\n",
    "            y_pred = y_pred.flatten()\n",
    "    else:\n",
    "        model.fit(X_train, y_train.flatten())\n",
    "        y_pred = model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "def plot_results(y_true, y_pred, y_temp_test, task_name, metric_name, save_path):\n",
    "    \"\"\"Plot results vs temperature\"\"\"\n",
    "    from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "    unique_temps = np.unique(y_temp_test)\n",
    "    metrics_by_temp, temps_list = [], []\n",
    "    for temp in unique_temps:\n",
    "        mask = (y_temp_test.flatten() == temp)\n",
    "        if np.sum(mask) > 0:\n",
    "            if task_name == 'classification':\n",
    "                metric = accuracy_score(y_true[mask], y_pred[mask])\n",
    "            else:\n",
    "                metric = mean_absolute_error(y_true[mask], y_pred[mask])\n",
    "            metrics_by_temp.append(metric)\n",
    "            temps_list.append(temp)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(temps_list, metrics_by_temp, 'o-', linewidth=2, markersize=8,\n",
    "            color='blue' if task_name == 'classification' else 'green')\n",
    "    plt.axvline(x=2.269, color='r', linestyle='--', linewidth=2, label='Tc = 2.269')\n",
    "    plt.xlabel('Temperature (T)', fontsize=12)\n",
    "    plt.ylabel(metric_name, fontsize=12)\n",
    "    plt.title(f'Task {\"A\" if task_name == \"classification\" else \"B\"}: {metric_name} vs Temperature', \n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11113b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Generate training and test data\n",
    "print(\"=\" * 60)\n",
    "print(\"Problem 2: Ising Model - Neural Network Tasks\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nGenerating training data...\")\n",
    "X_train, y_label_train, y_temp_train = generate_data(\n",
    "    size=25, num_temp=51, temp_min=1.0, temp_max=3.5, repeat=20, max_iter=625)\n",
    "print(\"\\nGenerating test data...\")\n",
    "X_test, y_label_test, y_temp_test = generate_data(\n",
    "    size=25, num_temp=21, temp_min=1.0, temp_max=3.5, repeat=20, max_iter=625)\n",
    "print(f\"\\nTraining: {X_train.shape[0]} samples, Test: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fec48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task A: Classification\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Task A: Classification\")\n",
    "print(\"=\" * 60)\n",
    "model, model_type = build_ising_model(X_train.shape[1], 'classification')\n",
    "plot_model_flowchart(\"Task A\", \"classification\", \"task_a_model_flowchart.png\")\n",
    "print(\"Training model...\")\n",
    "y_pred = train_and_evaluate(model, model_type, X_train, y_label_train, X_test, y_label_test, 'classification')\n",
    "y_true = y_label_test.flatten().astype(int)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"Overall Test Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "plot_results(y_true, y_pred, y_temp_test, 'classification', 'Test Accuracy', 'task_a_accuracy_vs_temp.png')\n",
    "print(\"Plot saved to task_a_accuracy_vs_temp.png\")\n",
    "print(\"Observations: Accuracy decreases near critical temperature (Tc = 2.269)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ca3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task B: Regression\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Task B: Regression\")\n",
    "print(\"=\" * 60)\n",
    "model, model_type = build_ising_model(X_train.shape[1], 'regression')\n",
    "plot_model_flowchart(\"Task B\", \"regression\", \"task_b_model_flowchart.png\")\n",
    "print(\"Training model...\")\n",
    "y_pred = train_and_evaluate(model, model_type, X_train, y_temp_train, X_test, y_temp_test, 'regression')\n",
    "y_true = y_temp_test.flatten()\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(f\"Overall Test MAE: {mean_absolute_error(y_true, y_pred):.4f}\")\n",
    "plot_results(y_true, y_pred, y_temp_test, 'regression', 'Test MAE', 'task_b_mae_vs_temp.png')\n",
    "print(\"Plot saved to task_b_mae_vs_temp.png\")\n",
    "print(\"Observations: MAE increases near critical temperature (Tc = 2.269)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d194447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All tasks completed!\")\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4s2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
